{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "232e6854",
   "metadata": {},
   "source": [
    "# EfficientNetB3 â€“ PlantVillage ðŸŒ±\n",
    "*Generated automatically on 2025-07-07 14:06*\n",
    "\n",
    "Este notebook entrena EfficientNetB3 en el dataset **PlantVillage**, realiza fineâ€‘tuning, evalÃºa el modelo y lo convierte a **CoreML** para usarlo en iOS/macOS.\n",
    "\n",
    "**Requisitos**: Mac con Apple Silicon (M1/M2/M3) y Python â‰¥ 3.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8365122f-ec43-4562-8d17-16906eadbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Enable Metal optimizations\n",
    "os.environ['TF_ENABLE_GPU_GARBAGE_COLLECTION'] = 'true'\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "os.environ['TF_USE_CUDNN_BATCHNORM_SPATIAL_PERSISTENT'] = '1'\n",
    "os.environ['TF_METAL_ENABLED_LOG_DEVICE_PLACEMENT'] = '0'  # Disable verbose logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a9a467c-90b5-4f3b-a514-fc86cdc14921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Optimizations:\n",
      "XLA Enabled: \n",
      "Grappler Enabled: {'disable_model_pruning': False, 'disable_meta_optimizer': False}\n",
      "Matrix multiplication result sum: -198371.62\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check optimization status\n",
    "print(\"GPU Optimizations:\")\n",
    "print(f\"XLA Enabled: {tf.config.optimizer.get_jit()}\")\n",
    "print(f\"Grappler Enabled: {tf.config.optimizer.get_experimental_options()}\")\n",
    "\n",
    "# Test GPU acceleration\n",
    "with tf.device('/GPU:0'):\n",
    "    a = tf.random.normal([10000, 10000])\n",
    "    b = tf.random.normal([10000, 10000])\n",
    "    c = tf.matmul(a, b)\n",
    "    print(\"Matrix multiplication result sum:\", tf.reduce_sum(c).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b06a5f4f-263e-4d04-ad56-8def113c64b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure advanced optimizations\n",
    "tf.config.optimizer.set_experimental_options({\n",
    "    'disable_model_pruning': False,\n",
    "    'constant_folding': True,\n",
    "    'shape_optimization': True,\n",
    "    'remapping': True,\n",
    "    'arithmetic_optimization': True,\n",
    "    'dependency_optimization': True,\n",
    "    'loop_optimization': True,\n",
    "    'function_optimization': True,\n",
    "    'debug_stripper': True,\n",
    "    'scoped_allocator_optimization': True,\n",
    "    'pin_to_host_optimization': True,\n",
    "    'implementation_selector': True,\n",
    "    'auto_mixed_precision': True,\n",
    "    'disable_meta_optimizer': False\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636ad052",
   "metadata": {},
   "source": [
    "## ParÃ¡metros globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eabc49ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49c9b4cc-e3b8-47b7-bad9-41645c94ebf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253d298f",
   "metadata": {},
   "source": [
    "## Preparar generadores de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "886c81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Parameters and Paths ---\n",
    "original_dir = os.path.expanduser(\"~/Desktop/Plantas/PlantVillage\")\n",
    "splits = ['train', 'val', 'test']\n",
    "split_ratios = (0.8, 0.1, 0.1)\n",
    "\n",
    "IMG_SIZE = 300\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_HEAD = 10\n",
    "EPOCHS_FINETUNE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8226578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Create train/val/test folders and copy images ---\n",
    "for split in splits:\n",
    "    os.makedirs(os.path.join(original_dir, split), exist_ok=True)\n",
    "\n",
    "for class_name in os.listdir(original_dir):\n",
    "    class_path = os.path.join(original_dir, class_name)\n",
    "    if not os.path.isdir(class_path) or class_name in splits:\n",
    "        continue\n",
    "\n",
    "    images = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    random.shuffle(images)\n",
    "\n",
    "    n_total = len(images)\n",
    "    n_train = int(n_total * split_ratios[0])\n",
    "    n_val = int(n_total * split_ratios[1])\n",
    "\n",
    "    split_dict = {\n",
    "        'train': images[:n_train],\n",
    "        'val': images[n_train:n_train+n_val],\n",
    "        'test': images[n_train+n_val:]\n",
    "    }\n",
    "\n",
    "    for split, split_images in split_dict.items():\n",
    "        split_dir = os.path.join(original_dir, split, class_name)\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "        for img_name in split_images:\n",
    "            src = os.path.join(class_path, img_name)\n",
    "            dst = os.path.join(split_dir, img_name)\n",
    "            if os.path.exists(src):\n",
    "                shutil.copy2(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc6e706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20638 images belonging to 16 classes.\n",
      "Found 20141 images belonging to 16 classes.\n",
      "Found 20166 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 3. Create data generators with augmentation ---\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    channel_shift_range=50,\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(original_dir, 'train'),\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    os.path.join(original_dir, 'val'),\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "    os.path.join(original_dir, 'test'),\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "NUM_CLASSES = len(train_generator.class_indices)\n",
    "class_names = list(train_generator.class_indices.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e312249e-2562-4734-b39f-2af966c17acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c830b522-e424-40b1-b6cb-066fbace6334",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 4. Enhanced Model Architecture with Attention ---\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "attention = layers.Dense(256, activation='sigmoid')(x) \n",
    "x = layers.multiply([x, attention])\n",
    "predictions = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = models.Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ed0417c-eb52-400d-a332-2918b8164a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 5. Class Weights ---\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_generator.classes), y=train_generator.classes)\n",
    "class_weights = dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37820f66-3b53-491c-b008-9020a29de274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 6. Callbacks and Learning Rate Schedule ---\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "initial_learning_rate = 1e-4\n",
    "decay_steps = EPOCHS_HEAD * len(train_generator)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=15, restore_best_weights=True, monitor='val_accuracy'),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=5, monitor='val_loss'),\n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint('models/best_model.h5', save_best_only=True)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94b7e921-b556-4161-af1c-556adf3184e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 13:25:49.216736: W tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:2303] No (suitable) GPUs detected, skipping auto_mixed_precision graph optimizer\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node GatherV2 defined at (most recent call last):\n<stack traces unavailable>\nindices[4] = 15 is not in [0, 15)\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_120855]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      4\u001b[39m optimizer = optimizers.Adam(lr_schedule)\n\u001b[32m      6\u001b[39m model.compile(optimizer=optimizer, \n\u001b[32m      7\u001b[39m               loss=\u001b[33m'\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      8\u001b[39m               metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      9\u001b[39m                       tf.keras.metrics.Precision(name=\u001b[33m'\u001b[39m\u001b[33mprecision\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     10\u001b[39m                       tf.keras.metrics.Recall(name=\u001b[33m'\u001b[39m\u001b[33mrecall\u001b[39m\u001b[33m'\u001b[39m)])\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS_HEAD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m          \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: Graph execution error:\n\nDetected at node GatherV2 defined at (most recent call last):\n<stack traces unavailable>\nindices[4] = 15 is not in [0, 15)\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_120855]"
     ]
    }
   ],
   "source": [
    "# --- 7. Training Head with Cosine Decay ---\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate, decay_steps)\n",
    "optimizer = optimizers.Adam(lr_schedule)\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', \n",
    "                      tf.keras.metrics.Precision(name='precision'),\n",
    "                      tf.keras.metrics.Recall(name='recall')])\n",
    "\n",
    "model.fit(train_generator, \n",
    "          epochs=EPOCHS_HEAD, \n",
    "          validation_data=val_generator, \n",
    "          callbacks=callbacks, \n",
    "          class_weight=class_weights, \n",
    "          verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b9b740-6250-45c1-9e9f-ddd386c7e96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Training Head with Cosine Decay ---\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate, decay_steps)\n",
    "optimizer = optimizers.Adam(lr_schedule)\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', \n",
    "                      tf.keras.metrics.Precision(name='precision'),\n",
    "                      tf.keras.metrics.Recall(name='recall')])\n",
    "\n",
    "model.fit(train_generator, \n",
    "          epochs=EPOCHS_HEAD, \n",
    "          validation_data=val_generator, \n",
    "          callbacks=callbacks, \n",
    "          class_weight=class_weights, \n",
    "          verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32737a6-a377-4d4c-a88a-23aa0c16c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 8. Fine-tuning ---\n",
    "model = tf.keras.models.load_model('models/best_model.h5')\n",
    "for layer in model.layers[-20:]:\n",
    "    if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(1e-5), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_generator, \n",
    "          validation_data=val_generator, \n",
    "          epochs=EPOCHS_FINETUNE, \n",
    "          callbacks=callbacks, \n",
    "          class_weight=class_weights, \n",
    "          verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b89e80d-1dd5-45ad-bdcc-15b68f6c30a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 9. Enhanced Evaluation ---\n",
    "def tta_predict(model, generator, steps=5):\n",
    "    preds = []\n",
    "    for _ in range(steps):\n",
    "        preds.append(model.predict(generator, verbose=0))\n",
    "    return np.mean(preds, axis=0)\n",
    "\n",
    "y_pred = tta_predict(model, test_generator)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "loss, acc, precision, recall = model.evaluate(test_generator)\n",
    "print(f\"\\nðŸŽ¯ Test accuracy: {acc:.4f}\")\n",
    "print(f\"ðŸŽ¯ Test precision: {precision:.4f}\")\n",
    "print(f\"ðŸŽ¯ Test recall: {recall:.4f}\")\n",
    "\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_true, y_pred_classes, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ceb8e8-28af-455f-ba19-92f252183c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "os.makedirs('reports', exist_ok=True)\n",
    "plt.savefig('reports/confusion_matrix.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1aa24b-2ff9-4eff-a964-908ca7478476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "y_test = label_binarize(y_true, classes=np.arange(NUM_CLASSES))\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(NUM_CLASSES):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "plt.figure()\n",
    "for i in range(NUM_CLASSES):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('reports/roc_curve.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9bf29a-7674-42b9-8e0a-579eddc81b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 10. Save final model and classes ---\n",
    "model.save('models/efficientnetb3_plantvillage_finetuned.h5')\n",
    "with open('models/class_names.json', 'w') as f:\n",
    "    json.dump(train_generator.class_indices, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b2f8e-f95e-4d5b-aa0a-bb193a416211",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- 11. Model Quantization ---\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "with open('models/efficientnetb3_plantvillage_quant.tflite', 'wb') as f:\n",
    "    f.write(tflite_quant_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38c9d1d-f251-40f0-b216-96e8e58e65e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- 12. Enhanced Gradio Interface ---\n",
    "treatment_info = {\n",
    "    \"healthy\": {\n",
    "        \"diagnosis\": \"Healthy plant\",\n",
    "        \"treatment\": \"No treatment needed. Maintain proper watering and sunlight.\",\n",
    "        \"prevention\": \"Continue current care regimen with regular monitoring.\"\n",
    "    },\n",
    "    \"powdery_mildew\": {\n",
    "        \"diagnosis\": \"Powdery Mildew infection\",\n",
    "        \"treatment\": \"Apply fungicides containing sulfur or potassium bicarbonate. Remove severely infected leaves.\",\n",
    "        \"prevention\": \"Improve air circulation, avoid overhead watering, and maintain proper plant spacing.\"\n",
    "    },\n",
    "    # Add more treatments as needed\n",
    "}\n",
    "\n",
    "def predict_image(img):\n",
    "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE)) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    prediction = model.predict(img)\n",
    "    class_idx = np.argmax(prediction)\n",
    "    \n",
    "    # Get top 3 predictions\n",
    "    top_classes = np.argsort(prediction[0])[-3:][::-1]\n",
    "    top_predictions = {class_names[i]: float(prediction[0][i]) for i in top_classes}\n",
    "    \n",
    "    # Get treatment info\n",
    "    current_class = class_names[class_idx]\n",
    "    treatment = treatment_info.get(current_class, {\n",
    "        \"diagnosis\": current_class,\n",
    "        \"treatment\": \"Consult with a plant pathologist for specific treatment options.\",\n",
    "        \"prevention\": \"Maintain good plant hygiene and monitor regularly.\"\n",
    "    })\n",
    "    \n",
    "    return {\n",
    "        \"predictions\": top_predictions,\n",
    "        \"diagnosis\": treatment[\"diagnosis\"],\n",
    "        \"treatment\": treatment[\"treatment\"],\n",
    "        \"prevention\": treatment[\"prevention\"],\n",
    "        \"confidence\": f\"{prediction[0][class_idx]*100:.1f}%\"\n",
    "    }\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=predict_image,\n",
    "    inputs=gr.Image(type=\"pil\", label=\"Upload Plant Leaf Image\"),\n",
    "    outputs=[\n",
    "        gr.Label(num_top_classes=3, label=\"Top Predictions\"),\n",
    "        gr.Textbox(label=\"Diagnosis\"),\n",
    "        gr.Textbox(label=\"Recommended Treatment\"),\n",
    "        gr.Textbox(label=\"Prevention Tips\"),\n",
    "        gr.Textbox(label=\"Confidence Level\")\n",
    "    ],\n",
    "    title=\"ðŸŒ± Plant Disease Classifier\",\n",
    "    description=\"Upload an image of a plant leaf to diagnose potential diseases and get treatment recommendations\",\n",
    "    examples=[[\"examples/healthy.jpg\"], [\"examples/diseased.jpg\"]],\n",
    "    theme=\"soft\",\n",
    "    allow_flagging=\"never\"\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bcd6c6",
   "metadata": {},
   "source": [
    "## Guardar modelo Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa556f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('efficientnetb3_plantvillage.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7eceaa",
   "metadata": {},
   "source": [
    "## ConversiÃ³n a CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c2f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools as ct\n",
    "# Convertir el modelo (entrada en formato ImagenRGB de 300x300)\n",
    "mlmodel = ct.convert(model, source='tensorflow', inputs=[ct.ImageType(shape=(1, IMG_SIZE, IMG_SIZE, 3))])\n",
    "mlmodel.save('efficientnetb3_plantvillage.mlmodel')\n",
    "print('Modelo CoreML guardado como efficientnetb3_plantvillage.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d89ca8-1f44-4784-acba-22b108028281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd72dc27-6f6d-48b0-9121-196f057f76b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50872c79-b258-4e56-a690-5e26e1da8027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6e970b-d906-4bd6-aefc-88f7f74d1ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee416ff-d4ff-4b8b-aa39-e3a56923623f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
